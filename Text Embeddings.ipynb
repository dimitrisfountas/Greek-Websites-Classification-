{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Challenge: Node Classification for Greek websites\n",
    "## Part: Text Embeddings\n",
    "\n",
    "<br />\n",
    "<div style=\"text-align: left\"> <b> Date: </b> June 2024 </div>\n",
    "\n",
    "---\n",
    "\n",
    "> Didimiotou-Kaoukaki Konstantina, ID: p3352206 <br />\n",
    "> Kortsinoglou Eirini, ID: p3352212 <br />\n",
    "> Fountas Dimitrios, ID: p3352228 <br />\n",
    "\n",
    "> MSc in Data Science (PT) <br />\n",
    "> Department of Informatics <br />\n",
    "> Athens University of Economics and Business <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-08T08:41:01.835208Z",
     "iopub.status.busy": "2024-06-08T08:41:01.834810Z",
     "iopub.status.idle": "2024-06-08T08:41:01.853538Z",
     "shell.execute_reply": "2024-06-08T08:41:01.852314Z",
     "shell.execute_reply.started": "2024-06-08T08:41:01.835174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/preprocessed-data-final/test_text_data.pkl\n",
      "/kaggle/input/preprocessed-data-final/train_text_data.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import re\n",
    "from io import BytesIO\n",
    "# !pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GREEK BERT - WORD EMBEDDINGS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly utilize the Greek Bert embeddings from https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T06:47:03.864476Z",
     "iopub.status.busy": "2024-06-08T06:47:03.863882Z",
     "iopub.status.idle": "2024-06-08T06:47:20.593777Z",
     "shell.execute_reply": "2024-06-08T06:47:20.592572Z",
     "shell.execute_reply.started": "2024-06-08T06:47:03.864443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbc14a50543491c98e5b3a0e379ad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe305996e6e4a63b37f4c708f2ed544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d68610c816d474faf091f73446e9060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d1e89db52c45f5b60604303feb2c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bd3a50b0ca40a78ad28972617232f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n",
    "model = AutoModel.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function processes the list of train and test texts in batches (for memory effiency purposes). \n",
    "It uses the pre-trained Greek Bert model, to generate the embeddings for each word in each sentence, and then each sentence is represented by averaging the word embeddings. \n",
    "\n",
    "As max length of the sentences, we define 512 tokens. So, sentences of size less than this will be padded to reach length of size 512 tokens, and sentences of size larger that 512 tokens, will be truncated to this length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T06:48:02.291855Z",
     "iopub.status.busy": "2024-06-08T06:48:02.291109Z",
     "iopub.status.idle": "2024-06-08T06:48:02.302655Z",
     "shell.execute_reply": "2024-06-08T06:48:02.301244Z",
     "shell.execute_reply.started": "2024-06-08T06:48:02.291819Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embeddings(text_list, tokenizer, max_length, batch_size):\n",
    "    \n",
    "    embeddings_list = []\n",
    "\n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Processing Batches\"):\n",
    "        batch_texts = text_list[i:i + batch_size]\n",
    "        encoding = tokenizer.batch_encode_plus(\n",
    "            batch_texts,                    # List of input texts\n",
    "            padding=True,                  # Pad to the maximum sequence length\n",
    "            truncation=True,              # Truncate to the maximum sequence length if necessary\n",
    "            max_length = max_length,\n",
    "            return_tensors='pt',        # Return PyTorch tensors\n",
    "            add_special_tokens=True    # Add special tokens CLS and SEP\n",
    "        )\n",
    " \n",
    "        input_ids = encoding['input_ids']  # Token IDs\n",
    "        attention_mask = encoding['attention_mask']  # Attention mask\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "            embeddings_list.append(embeddings)\n",
    "        # Concatenate all batch embeddings\n",
    "    \n",
    "    embeddings = torch.cat(embeddings_list, dim=0)    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T06:50:19.406828Z",
     "iopub.status.busy": "2024-06-08T06:50:19.406340Z",
     "iopub.status.idle": "2024-06-08T06:50:20.584950Z",
     "shell.execute_reply": "2024-06-08T06:50:20.583619Z",
     "shell.execute_reply.started": "2024-06-08T06:50:19.406793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load preprocessed data from the pickle file\n",
    "with open('/kaggle/input/preprocessed-data-final/train_text_data.pkl', 'rb') as f:\n",
    "    train_text_data = pickle.load(f)\n",
    "    \n",
    "with open('/kaggle/input/preprocessed-data-final/test_text_data.pkl', 'rb') as f:\n",
    "    test_text_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T06:50:40.008932Z",
     "iopub.status.busy": "2024-06-08T06:50:40.008085Z",
     "iopub.status.idle": "2024-06-08T06:50:40.015352Z",
     "shell.execute_reply": "2024-06-08T06:50:40.014111Z",
     "shell.execute_reply.started": "2024-06-08T06:50:40.008892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1812\n",
      "605\n"
     ]
    }
   ],
   "source": [
    "print(len(train_text_data))\n",
    "print(len(test_text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T06:51:12.718433Z",
     "iopub.status.busy": "2024-06-08T06:51:12.717165Z",
     "iopub.status.idle": "2024-06-08T07:41:24.723917Z",
     "shell.execute_reply": "2024-06-08T07:41:24.721774Z",
     "shell.execute_reply.started": "2024-06-08T06:51:12.718380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 4/4 [37:35<00:00, 563.91s/it]\n",
      "Processing Batches: 100%|██████████| 2/2 [12:36<00:00, 378.08s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings_train = get_embeddings(train_text_data, tokenizer, 512, 500)\n",
    "embeddings_test = get_embeddings(test_text_data, tokenizer, 512, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the embeddings as pickle files, to be used in the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T07:55:33.579191Z",
     "iopub.status.busy": "2024-06-08T07:55:33.577432Z",
     "iopub.status.idle": "2024-06-08T07:55:33.609140Z",
     "shell.execute_reply": "2024-06-08T07:55:33.607510Z",
     "shell.execute_reply.started": "2024-06-08T07:55:33.579138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bert embeddings\n",
    "with open('train_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_train, f)\n",
    "    \n",
    "with open('test_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers (based on Greek Bert) - Sentence Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, we also create embeddings using another Bert-based pre-trained model, which is trained on Greek media texts, and can be found in this link: https://huggingface.co/dimitriz/st-greek-media-bert-base-uncased  \n",
    "In this case, we utilize the model as Sentence Tokenizer, which produces the embeddings for each sentence on the train and on the text datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T07:59:38.161458Z",
     "iopub.status.busy": "2024-06-08T07:59:38.159663Z",
     "iopub.status.idle": "2024-06-08T07:59:49.773278Z",
     "shell.execute_reply": "2024-06-08T07:59:49.771825Z",
     "shell.execute_reply.started": "2024-06-08T07:59:38.161409Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507653d5515e41d6a0e197e2f699a821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ddc17308b54822925ae9782ca3ae4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/452M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745c1b7433954751ba7d74439c6b933d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d321911934e349d89c008623afb48be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5670dc5f20f4523b8fab6e61884362f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a2e3ab2bb0412892a61750d906fe77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb_model = SentenceTransformer('dimitriz/greek-media-bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T08:05:42.216697Z",
     "iopub.status.busy": "2024-06-08T08:05:42.216149Z",
     "iopub.status.idle": "2024-06-08T08:41:01.832444Z",
     "shell.execute_reply": "2024-06-08T08:41:01.831105Z",
     "shell.execute_reply.started": "2024-06-08T08:05:42.216657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9e9da410184619993bbf2edd7626e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d587afbea840b68d2fe8fe4e44e002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_train = emb_model.encode(train_text_data, show_progress_bar=True,\n",
    "                              batch_size=128)\n",
    "embed_test = emb_model.encode(test_text_data, show_progress_bar=True,\n",
    "                              batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T08:44:48.414274Z",
     "iopub.status.busy": "2024-06-08T08:44:48.413729Z",
     "iopub.status.idle": "2024-06-08T08:44:48.432847Z",
     "shell.execute_reply": "2024-06-08T08:44:48.431492Z",
     "shell.execute_reply.started": "2024-06-08T08:44:48.414236Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('train_embed_sent.pkl', 'wb') as f:\n",
    "    pickle.dump(embed_train, f)\n",
    "    \n",
    "with open('test_embed_sent.pkl', 'wb') as f:\n",
    "    pickle.dump(embed_test, f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5170033,
     "sourceId": 8633981,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
